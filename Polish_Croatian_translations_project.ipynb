{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP3Fim1yjR9GGgA3Vftn+xP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edzix-1/NLP-Project/blob/main/Polish_Croatian_translations_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code responsible for downloading and unpacking the data"
      ],
      "metadata": {
        "id": "ByeBWyJiwyTN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONcB2b4cKMHQ",
        "outputId": "4e5eb858-09e4-4bc1-c058-774577a53343"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download complete\n"
          ]
        }
      ],
      "source": [
        "import urllib.request\n",
        "\n",
        "url = \"https://object.pouta.csc.fi/OPUS-MultiParaCrawl/v7.1/moses/hr-pl.txt.zip\"\n",
        "output_path = \"opus_pl_hr.zip\"\n",
        "\n",
        "urllib.request.urlretrieve(url, output_path)\n",
        "print(\"Download complete\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -o opus_pl_hr.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfeg0FSHKfqq",
        "outputId": "555557b7-76f2-4198-cc20-42555f972d30"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  opus_pl_hr.zip\n",
            "  inflating: README                  \n",
            "  inflating: LICENSE                 \n",
            "  inflating: MultiParaCrawl.hr-pl.hr  \n",
            "  inflating: MultiParaCrawl.hr-pl.pl  \n",
            "  inflating: MultiParaCrawl.hr-pl.xml  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "with open(\"MultiParaCrawl.hr-pl.hr\", \"r\", encoding=\"utf-8\") as f: hr = f.read().splitlines()\n",
        "with open(\"MultiParaCrawl.hr-pl.pl\", \"r\", encoding=\"utf-8\") as f: pl = f.read().splitlines()\n",
        "\n",
        "df = pd.DataFrame({\"hr\": hr, \"pl\": pl})\n",
        "n = 5"
      ],
      "metadata": {
        "id": "vxtETUgSKhYG"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[5:]\n",
        "pl = pl[5:]\n",
        "hr = hr[5:]"
      ],
      "metadata": {
        "id": "Sewa6IgeJmJX"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multilingual model and tokenizer declaration. Creating the translate function for the Multilingual model."
      ],
      "metadata": {
        "id": "L18RGgZJw_fx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
        "\n",
        "model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
        "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
        "\n",
        "def translate_multi(sentences, src_lang, tgt_lang):\n",
        "    output = []\n",
        "    tokenizer.src_lang = src_lang\n",
        "    for sentence in sentences:\n",
        "      encoded = tokenizer(sentence, return_tensors=\"pt\")\n",
        "\n",
        "      generated_tokens = model.generate(\n",
        "          **encoded,\n",
        "          forced_bos_token_id=tokenizer.lang_code_to_id[tgt_lang]\n",
        "      )\n",
        "      output.append(tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0])\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "a93a3fdf703a4f35abcb39b1f9c0202a",
            "15d10307e4914a5d90e16468be3fcc30",
            "1dbe04bd585b4d808d21c0ad94b5b785",
            "8ff5a25144d2495eb07fb429ecf204b3",
            "f56b237667eb41159760db573a8b3e3b",
            "823eb748b287456ea410ddcbbd118e44",
            "bc819946709642f5b4d2c80ce172fb3e",
            "36f8b0870e1441eebf4d7dd8952a5cc6",
            "bcd89c1ec05e4ce9ab530fc7db4a5258",
            "fea2ece3eb22423381c2cac7519f1fe2",
            "4e93740c99bf4edea113fc24b868d017"
          ]
        },
        "id": "pxYsv_h-U_yJ",
        "outputId": "11591723-ffc2-420b-b2a1-c048f7ed08ed"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/516 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a93a3fdf703a4f35abcb39b1f9c0202a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Back-and-forth translations and evaluations for the Multilingual model"
      ],
      "metadata": {
        "id": "vBRnNPQjxObV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hr_to_pl = translate_multi(hr[:n], \"hr_HR\", \"pl_PL\")"
      ],
      "metadata": {
        "id": "U6giNUFQwBCK"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_score = 0\n",
        "for i in range(n):\n",
        "  bleu = sentence_bleu([pl[:n][i].split(' ')], hr_to_pl[i].split(' '))\n",
        "  total_score += bleu\n",
        "print(\"BLEU score: \", total_score/n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Exqw86HjTap",
        "outputId": "b575860d-6a6e-434b-f00e-1723e405db9c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score:  0.1221009811312018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pl_back = translate_multi(hr_to_pl, \"pl_PL\", \"hr_HR\")\n",
        "total_score = 0\n",
        "for i in range(n):\n",
        "  bleu = sentence_bleu([hr[:n][i].split(' ')], pl_back[i].split(' '))\n",
        "  total_score += bleu\n",
        "print(\"BLEU score: \", total_score/n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDXrqWfcPT-_",
        "outputId": "febff8ac-bc1f-43a4-9129-a43ffa87e6bf"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score:  8.190192597872934e-79\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pl_to_hr = translate_multi(pl[:n], \"pl_PL\", \"hr_HR\")\n",
        "total_score = 0\n",
        "for i in range(n):\n",
        "  bleu = sentence_bleu([pl[:n][i].split(' ')], pl_to_hr[i].split(' '))\n",
        "  total_score += bleu\n",
        "print(\"BLEU score: \", total_score/n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhlWrkgCPKM3",
        "outputId": "518fdebf-3a01-4c86-833c-e796c4ae3baa"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score:  5.842906353411464e-232\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hr_back = translate_multi(pl_to_hr, \"hr_HR\", \"pl_PL\")\n",
        "total_score = 0\n",
        "for i in range(n):\n",
        "  bleu = sentence_bleu([hr[:n][i].split(' ')], hr_back[i].split(' '))\n",
        "  total_score += bleu\n",
        "print(\"BLEU score: \", total_score/n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fw3snAXSTGlG",
        "outputId": "97318664-2604-47ea-c54e-cc0a268dd639"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score:  1.9189006110305264e-232\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Translations through English"
      ],
      "metadata": {
        "id": "IN_LI0X5xeIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ht_to_en = translate_multi(hr[:n], \"hr_HR\", \"en_XX\")\n",
        "en_to_pl = translate_multi(ht_to_en, \"en_XX\", \"pl_PL\")\n",
        "total_score = 0\n",
        "for i in range(n):\n",
        "  bleu = sentence_bleu([pl[:n][i].split(' ')], en_to_pl[i].split(' '))\n",
        "  total_score += bleu\n",
        "print(\"BLEU score: \", total_score/n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHvFv316XAj5",
        "outputId": "e2628023-d2f3-4242-ff46-0a9067fbb0b2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score:  0.08927291841594476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Slavic model and tokenizer declaration. Creating the translate function for the Slavic model."
      ],
      "metadata": {
        "id": "2NaQU_N3xjbf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "\n",
        "model_name = 'Helsinki-NLP/opus-mt-sla-sla'\n",
        "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "model = MarianMTModel.from_pretrained(model_name)\n",
        "def translate(text, trg_lang):\n",
        "    text = \">>\" + trg_lang + \"<< \" + text\n",
        "    translated = model.generate(**tokenizer(text, return_tensors='pt', padding=True))\n",
        "\n",
        "    translated_text = tokenizer.decode(translated[0], skip_special_tokens=True)\n",
        "\n",
        "    return translated_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "75bea4a0274647389b85bb70591156ef",
            "90205865eaf94b3385ee729181cbc22f",
            "6be5831c0b6042b2a9b22e9d80bd8534",
            "8bc3c4dc553b4f67aa5c128bc3269c1e",
            "ac1ce48516f546f3816f70ebb0a37250",
            "a4a8687aafd24ca798f72620735a726e",
            "46ce4991286c42bfaaf375bd855384b4",
            "35eff61a48974f789f416acc2c361037",
            "d5000ca24fa0463482b9735bc11963be",
            "22cf99591b124d3faf2e33b45171f508",
            "278b2d896ca84b45a883c27fb9f112d9"
          ]
        },
        "id": "1CdJVZqZOLfZ",
        "outputId": "816f753c-86d1-4e95-da5d-e7dd65b7be39"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/models/marian/tokenization_marian.py:176: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/258 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "75bea4a0274647389b85bb70591156ef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tied weights mapping and config for this model specifies to tie model.shared.weight to model.decoder.embed_tokens.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n",
            "The tied weights mapping and config for this model specifies to tie model.shared.weight to model.encoder.embed_tokens.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Back-and-forth translations and evaluations for the Slavic model"
      ],
      "metadata": {
        "id": "ZZACIM5KyNK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hr_to_pl2 = []\n",
        "for i in range(n):\n",
        "  hr_to_pl2.append(translate(hr[i], \"pol\"))\n",
        "\n",
        "total_score = 0\n",
        "for i in range(n):\n",
        "  bleu = sentence_bleu([pl[:n][i].split(' ')], hr_to_pl2[i].split(' '))\n",
        "  total_score += bleu\n",
        "print(\"BLEU score: \", total_score/n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AuZe2Fk_G7d",
        "outputId": "ce8f2557-bba0-441f-9e78-3eb5ebdaeffc"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score:  0.25232520155621585\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pl_to_hr2 = []\n",
        "for i in range(n):\n",
        "  pl_to_hr2.append(translate(pl[i], \"hrv\"))\n",
        "\n",
        "total_score = 0\n",
        "for i in range(n):\n",
        "  bleu = sentence_bleu([hr[:n][i].split(' ')], pl_to_hr2[i].split(' '))\n",
        "  total_score += bleu\n",
        "print(\"BLEU score: \", total_score/n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Jp9YGPEioBs",
        "outputId": "fc50aa1c-d7cc-4618-ad94-8b70a8c63736"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score:  0.22217223648086906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hr_back2 = []\n",
        "for i in range(n):\n",
        "  hr_back2.append(translate(pl_to_hr2[i], \"pol\"))\n",
        "\n",
        "total_score = 0\n",
        "for i in range(n):\n",
        "  bleu = sentence_bleu([pl[:n][i].split(' ')], hr_back2[i].split(' '))\n",
        "  total_score += bleu\n",
        "print(\"BLEU score: \", total_score/n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bye3w8jslisT",
        "outputId": "3f17cbad-0964-4060-84c7-c3d79fc87145"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score:  0.1481594145679185\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pl_back2 = []\n",
        "for i in range(n):\n",
        "  pl_back2.append(translate(hr_to_pl2[i], \"hrv\"))\n",
        "\n",
        "total_score = 0\n",
        "for i in range(n):\n",
        "  bleu = sentence_bleu([hr[:n][i].split(' ')], pl_back2[i].split(' '))\n",
        "  total_score += bleu\n",
        "print(\"BLEU score: \", total_score/n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llOL1aYsndIZ",
        "outputId": "99d4df61-3d53-4ecf-d9e8-5b5572912eb0"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score:  0.07084840876066213\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text results"
      ],
      "metadata": {
        "id": "41bQqU9CYwoq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "samples = pd.DataFrame({\n",
        "    'Original Polish': pl[:5],\n",
        "    'Reference Croatian': hr[:5],\n",
        "    'mBART-50 Translation Polish': hr_to_pl[:5],\n",
        "    'mBART-50 Translation Croatian': pl_to_hr[:5],\n",
        "    'MarianMT Translation Polish': hr_to_pl2[:5],\n",
        "    'MarianMT Translation Croatian': pl_to_hr2[:5]\n",
        "})\n",
        "\n",
        "display(samples.style.set_properties(**{'text-align': 'left'}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "id": "r9HcZCVMICop",
        "outputId": "bb221ba3-1038-4952-f52a-87316cf02769"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7b624bcf3440>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_bd0c9_row0_col0, #T_bd0c9_row0_col1, #T_bd0c9_row0_col2, #T_bd0c9_row0_col3, #T_bd0c9_row0_col4, #T_bd0c9_row0_col5, #T_bd0c9_row1_col0, #T_bd0c9_row1_col1, #T_bd0c9_row1_col2, #T_bd0c9_row1_col3, #T_bd0c9_row1_col4, #T_bd0c9_row1_col5, #T_bd0c9_row2_col0, #T_bd0c9_row2_col1, #T_bd0c9_row2_col2, #T_bd0c9_row2_col3, #T_bd0c9_row2_col4, #T_bd0c9_row2_col5, #T_bd0c9_row3_col0, #T_bd0c9_row3_col1, #T_bd0c9_row3_col2, #T_bd0c9_row3_col3, #T_bd0c9_row3_col4, #T_bd0c9_row3_col5, #T_bd0c9_row4_col0, #T_bd0c9_row4_col1, #T_bd0c9_row4_col2, #T_bd0c9_row4_col3, #T_bd0c9_row4_col4, #T_bd0c9_row4_col5 {\n",
              "  text-align: left;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_bd0c9\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_bd0c9_level0_col0\" class=\"col_heading level0 col0\" >Original Polish</th>\n",
              "      <th id=\"T_bd0c9_level0_col1\" class=\"col_heading level0 col1\" >Reference Croatian</th>\n",
              "      <th id=\"T_bd0c9_level0_col2\" class=\"col_heading level0 col2\" >mBART-50 Translation Polish</th>\n",
              "      <th id=\"T_bd0c9_level0_col3\" class=\"col_heading level0 col3\" >mBART-50 Translation Croatian</th>\n",
              "      <th id=\"T_bd0c9_level0_col4\" class=\"col_heading level0 col4\" >MarianMT Translation Polish</th>\n",
              "      <th id=\"T_bd0c9_level0_col5\" class=\"col_heading level0 col5\" >MarianMT Translation Croatian</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_bd0c9_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_bd0c9_row0_col0\" class=\"data row0 col0\" >Błędna jest opinia, że rozwój mowy rozpoczyna się od momentu pierwszych słów. </td>\n",
              "      <td id=\"T_bd0c9_row0_col1\" class=\"data row0 col1\" >Pogrešno je mišljenje da razvoj govora počinje od trenutka prvih riječi. </td>\n",
              "      <td id=\"T_bd0c9_row0_col2\" class=\"data row0 col2\" >Błędnie uważamy, że rozwój języka zaczyna się od momentu pierwszych słów.</td>\n",
              "      <td id=\"T_bd0c9_row0_col3\" class=\"data row0 col3\" >Błędna je ideja da se razvoj govora počinje od trenutka prve riječi.</td>\n",
              "      <td id=\"T_bd0c9_row0_col4\" class=\"data row0 col4\" >Niewłaściwe jest opinia, że rozwój mowy zaczyna się od momentu pierwszych słów.</td>\n",
              "      <td id=\"T_bd0c9_row0_col5\" class=\"data row0 col5\" >Pogrešno je zaključiti da je razvoj govora počeo od početka prvih riječi.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_bd0c9_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_bd0c9_row1_col0\" class=\"data row1 col0\" >Jednak jeśli jesteś jednym z bezwłosy lub utrata włosów wokół osoby, czynnik potencjalnie nie jest faktycznie największym zmartwieniem swoją dzisiaj. </td>\n",
              "      <td id=\"T_bd0c9_row1_col1\" class=\"data row1 col1\" >Ipak, ako ste jedan od dlaka ili gubitak ljudi kose oko, razlog potencijalno zapravo nije vaša najveća briga danas. </td>\n",
              "      <td id=\"T_bd0c9_row1_col2\" class=\"data row1 col2\" >Jednak, if you're one of the hair-losers, the reason, potentially, isn't your biggest concern today.</td>\n",
              "      <td id=\"T_bd0c9_row1_col3\" class=\"data row1 col3\" >No, if you are one of baldness or hair loss around a person, the factor potentially isn’t actually your biggest concern today.</td>\n",
              "      <td id=\"T_bd0c9_row1_col4\" class=\"data row1 col4\" >Mimo to, jeśli jesteś jednym z włosów lub straty ludzi, to powód potencjalnie nie jest twoim największym problemem dzisiaj.</td>\n",
              "      <td id=\"T_bd0c9_row1_col5\" class=\"data row1 col5\" >Međutim, ako ste jedan od bezkosa ili gubitak kose oko osobe, potencijalno nije zapravo najveća zabrinutost danas.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_bd0c9_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_bd0c9_row2_col0\" class=\"data row2 col0\" >Wojna dopiero się zaczyna... </td>\n",
              "      <td id=\"T_bd0c9_row2_col1\" class=\"data row2 col1\" >Rat je tek počeo... </td>\n",
              "      <td id=\"T_bd0c9_row2_col2\" class=\"data row2 col2\" >Wojna dopiero się rozpoczęła...</td>\n",
              "      <td id=\"T_bd0c9_row2_col3\" class=\"data row2 col3\" >Wojna tek počinje...</td>\n",
              "      <td id=\"T_bd0c9_row2_col4\" class=\"data row2 col4\" >Wojna dopiero się zaczęła.</td>\n",
              "      <td id=\"T_bd0c9_row2_col5\" class=\"data row2 col5\" >Rat je tek počeo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_bd0c9_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_bd0c9_row3_col0\" class=\"data row3 col0\" >Upadek Turtle prowadzi spadkobierców w przeglądzie woli Westinga, aby pozbyć się prawdziwego znaczenia. </td>\n",
              "      <td id=\"T_bd0c9_row3_col1\" class=\"data row3 col1\" >Pada djelovanje Kornjača vodi nasljednike u pregledu Westingove volje kako bi razjasnio svoje pravo značenje. </td>\n",
              "      <td id=\"T_bd0c9_row3_col2\" class=\"data row3 col2\" >The dropping of the Koran leads to a review of Westing's will to clarify its true meaning.</td>\n",
              "      <td id=\"T_bd0c9_row3_col3\" class=\"data row3 col3\" >Turtle's fall leads heirs to a review of Westing's will to get rid of his true significance.</td>\n",
              "      <td id=\"T_bd0c9_row3_col4\" class=\"data row3 col4\" >Działanie żółwia prowadzi spadkobierców do przeglądu woli Westinga, by wyjaśnić swoje prawdziwe znaczenie.</td>\n",
              "      <td id=\"T_bd0c9_row3_col5\" class=\"data row3 col5\" >Opadanje kornjače vodi nasljednike u pregledu volje Westing da se riješi pravog značenja.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_bd0c9_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_bd0c9_row4_col0\" class=\"data row4 col0\" >Średnia ocena naszych byłych uczniów, na pytanie o ich cały pobyt w szkole w Frankfurt </td>\n",
              "      <td id=\"T_bd0c9_row4_col1\" class=\"data row4 col1\" >Prosječna ocjena od naših bivših učenika, kada smo ih pitali za njihov ukupan boravak u školi u Frankfurt </td>\n",
              "      <td id=\"T_bd0c9_row4_col2\" class=\"data row4 col2\" >Średnia ocena naszych byłych uczniów, kiedy pytaliśmy o ich uczęszczanie do szkoły w Frankfurt.</td>\n",
              "      <td id=\"T_bd0c9_row4_col3\" class=\"data row4 col3\" >Średnja ocena naših bivših studenata, na pitanje o njihovom cijelom stayu u školi u Frankfurtu</td>\n",
              "      <td id=\"T_bd0c9_row4_col4\" class=\"data row4 col4\" >Średnia ocena naszych byłych uczniów, kiedy zapytaliśmy ich o ich wspólne pobyt w szkole w Frankfurt</td>\n",
              "      <td id=\"T_bd0c9_row4_col5\" class=\"data row4 col5\" >Prosječna procjena naših bivših učenika, na pitanje o njihovom cijelom boravku u školi u Frankfurtu</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}
