{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ByeBWyJiwyTN"
   },
   "source": [
    "Code responsible for downloading and unpacking the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ONcB2b4cKMHQ",
    "outputId": "4e5eb858-09e4-4bc1-c058-774577a53343"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download complete\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "url = \"https://object.pouta.csc.fi/OPUS-MultiParaCrawl/v7.1/moses/hr-pl.txt.zip\"\n",
    "output_path = \"opus_pl_hr.zip\"\n",
    "\n",
    "urllib.request.urlretrieve(url, output_path)\n",
    "print(\"Download complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cfeg0FSHKfqq",
    "outputId": "555557b7-76f2-4198-cc20-42555f972d30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  opus_pl_hr.zip\n",
      "  inflating: README                  \n",
      "  inflating: LICENSE                 \n",
      "  inflating: MultiParaCrawl.hr-pl.hr  \n",
      "  inflating: MultiParaCrawl.hr-pl.pl  \n",
      "  inflating: MultiParaCrawl.hr-pl.xml  \n"
     ]
    }
   ],
   "source": [
    "!unzip -o opus_pl_hr.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "vxtETUgSKhYG"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "with open(\"MultiParaCrawl.hr-pl.hr\", \"r\", encoding=\"utf-8\") as f: hr = f.read().splitlines()\n",
    "with open(\"MultiParaCrawl.hr-pl.pl\", \"r\", encoding=\"utf-8\") as f: pl = f.read().splitlines()\n",
    "\n",
    "df = pd.DataFrame({\"hr\": hr, \"pl\": pl})\n",
    "n = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Sewa6IgeJmJX"
   },
   "outputs": [],
   "source": [
    "df = df[5:]\n",
    "pl = pl[5:]\n",
    "hr = hr[5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L18RGgZJw_fx"
   },
   "source": [
    "Multilingual model and tokenizer declaration. Creating the translate function for the Multilingual model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "a93a3fdf703a4f35abcb39b1f9c0202a",
      "15d10307e4914a5d90e16468be3fcc30",
      "1dbe04bd585b4d808d21c0ad94b5b785",
      "8ff5a25144d2495eb07fb429ecf204b3",
      "f56b237667eb41159760db573a8b3e3b",
      "823eb748b287456ea410ddcbbd118e44",
      "bc819946709642f5b4d2c80ce172fb3e",
      "36f8b0870e1441eebf4d7dd8952a5cc6",
      "bcd89c1ec05e4ce9ab530fc7db4a5258",
      "fea2ece3eb22423381c2cac7519f1fe2",
      "4e93740c99bf4edea113fc24b868d017"
     ]
    },
    "id": "pxYsv_h-U_yJ",
    "outputId": "11591723-ffc2-420b-b2a1-c048f7ed08ed"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a93a3fdf703a4f35abcb39b1f9c0202a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/516 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "\n",
    "model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "\n",
    "def translate_multi(sentences, src_lang, tgt_lang):\n",
    "    output = []\n",
    "    tokenizer.src_lang = src_lang\n",
    "    for sentence in sentences:\n",
    "      encoded = tokenizer(sentence, return_tensors=\"pt\")\n",
    "\n",
    "      generated_tokens = model.generate(\n",
    "          **encoded,\n",
    "          forced_bos_token_id=tokenizer.lang_code_to_id[tgt_lang]\n",
    "      )\n",
    "      output.append(tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0])\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBRnNPQjxObV"
   },
   "source": [
    "Back-and-forth translations and evaluations for the Multilingual model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "U6giNUFQwBCK"
   },
   "outputs": [],
   "source": [
    "hr_to_pl = translate_multi(hr[:n], \"hr_HR\", \"pl_PL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Exqw86HjTap",
    "outputId": "b575860d-6a6e-434b-f00e-1723e405db9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score:  0.1221009811312018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "total_score = 0\n",
    "for i in range(n):\n",
    "  bleu = sentence_bleu([pl[:n][i].split(' ')], hr_to_pl[i].split(' '))\n",
    "  total_score += bleu\n",
    "print(\"BLEU score: \", total_score/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pDXrqWfcPT-_",
    "outputId": "febff8ac-bc1f-43a4-9129-a43ffa87e6bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score:  8.190192597872934e-79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.12/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "pl_back = translate_multi(hr_to_pl, \"pl_PL\", \"hr_HR\")\n",
    "total_score = 0\n",
    "for i in range(n):\n",
    "  bleu = sentence_bleu([hr[:n][i].split(' ')], pl_back[i].split(' '))\n",
    "  total_score += bleu\n",
    "print(\"BLEU score: \", total_score/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BhlWrkgCPKM3",
    "outputId": "518fdebf-3a01-4c86-833c-e796c4ae3baa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score:  5.842906353411464e-232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.12/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.12/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "pl_to_hr = translate_multi(pl[:n], \"pl_PL\", \"hr_HR\")\n",
    "total_score = 0\n",
    "for i in range(n):\n",
    "  bleu = sentence_bleu([pl[:n][i].split(' ')], pl_to_hr[i].split(' '))\n",
    "  total_score += bleu\n",
    "print(\"BLEU score: \", total_score/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fw3snAXSTGlG",
    "outputId": "97318664-2604-47ea-c54e-cc0a268dd639"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score:  1.9189006110305264e-232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.12/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.12/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "hr_back = translate_multi(pl_to_hr, \"hr_HR\", \"pl_PL\")\n",
    "total_score = 0\n",
    "for i in range(n):\n",
    "  bleu = sentence_bleu([hr[:n][i].split(' ')], hr_back[i].split(' '))\n",
    "  total_score += bleu\n",
    "print(\"BLEU score: \", total_score/n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IN_LI0X5xeIp"
   },
   "source": [
    "Translations through English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MHvFv316XAj5",
    "outputId": "e2628023-d2f3-4242-ff46-0a9067fbb0b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score:  0.08927291841594476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.12/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "ht_to_en = translate_multi(hr[:n], \"hr_HR\", \"en_XX\")\n",
    "en_to_pl = translate_multi(ht_to_en, \"en_XX\", \"pl_PL\")\n",
    "total_score = 0\n",
    "for i in range(n):\n",
    "  bleu = sentence_bleu([pl[:n][i].split(' ')], en_to_pl[i].split(' '))\n",
    "  total_score += bleu\n",
    "print(\"BLEU score: \", total_score/n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2NaQU_N3xjbf"
   },
   "source": [
    "Slavic model and tokenizer declaration. Creating the translate function for the Slavic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138,
     "referenced_widgets": [
      "75bea4a0274647389b85bb70591156ef",
      "90205865eaf94b3385ee729181cbc22f",
      "6be5831c0b6042b2a9b22e9d80bd8534",
      "8bc3c4dc553b4f67aa5c128bc3269c1e",
      "ac1ce48516f546f3816f70ebb0a37250",
      "a4a8687aafd24ca798f72620735a726e",
      "46ce4991286c42bfaaf375bd855384b4",
      "35eff61a48974f789f416acc2c361037",
      "d5000ca24fa0463482b9735bc11963be",
      "22cf99591b124d3faf2e33b45171f508",
      "278b2d896ca84b45a883c27fb9f112d9"
     ]
    },
    "id": "1CdJVZqZOLfZ",
    "outputId": "816f753c-86d1-4e95-da5d-e7dd65b7be39"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/models/marian/tokenization_marian.py:176: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75bea4a0274647389b85bb70591156ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/258 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tied weights mapping and config for this model specifies to tie model.shared.weight to model.decoder.embed_tokens.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n",
      "The tied weights mapping and config for this model specifies to tie model.shared.weight to model.encoder.embed_tokens.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n"
     ]
    }
   ],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "model_name = 'Helsinki-NLP/opus-mt-sla-sla'\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "def translate(text, trg_lang):\n",
    "    text = \">>\" + trg_lang + \"<< \" + text\n",
    "    translated = model.generate(**tokenizer(text, return_tensors='pt', padding=True))\n",
    "\n",
    "    translated_text = tokenizer.decode(translated[0], skip_special_tokens=True)\n",
    "\n",
    "    return translated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZACIM5KyNK9"
   },
   "source": [
    "Back-and-forth translations and evaluations for the Slavic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9AuZe2Fk_G7d",
    "outputId": "ce8f2557-bba0-441f-9e78-3eb5ebdaeffc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score:  0.25232520155621585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.12/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "hr_to_pl2 = []\n",
    "for i in range(n):\n",
    "  hr_to_pl2.append(translate(hr[i], \"pol\"))\n",
    "\n",
    "total_score = 0\n",
    "for i in range(n):\n",
    "  bleu = sentence_bleu([pl[:n][i].split(' ')], hr_to_pl2[i].split(' '))\n",
    "  total_score += bleu\n",
    "print(\"BLEU score: \", total_score/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Jp9YGPEioBs",
    "outputId": "fc50aa1c-d7cc-4618-ad94-8b70a8c63736"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score:  0.22217223648086906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.12/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "pl_to_hr2 = []\n",
    "for i in range(n):\n",
    "  pl_to_hr2.append(translate(pl[i], \"hrv\"))\n",
    "\n",
    "total_score = 0\n",
    "for i in range(n):\n",
    "  bleu = sentence_bleu([hr[:n][i].split(' ')], pl_to_hr2[i].split(' '))\n",
    "  total_score += bleu\n",
    "print(\"BLEU score: \", total_score/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bye3w8jslisT",
    "outputId": "3f17cbad-0964-4060-84c7-c3d79fc87145"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score:  0.1481594145679185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "hr_back2 = []\n",
    "for i in range(n):\n",
    "  hr_back2.append(translate(pl_to_hr2[i], \"pol\"))\n",
    "\n",
    "total_score = 0\n",
    "for i in range(n):\n",
    "  bleu = sentence_bleu([pl[:n][i].split(' ')], hr_back2[i].split(' '))\n",
    "  total_score += bleu\n",
    "print(\"BLEU score: \", total_score/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "llOL1aYsndIZ",
    "outputId": "99d4df61-3d53-4ecf-d9e8-5b5572912eb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score:  0.07084840876066213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.12/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "pl_back2 = []\n",
    "for i in range(n):\n",
    "  pl_back2.append(translate(hr_to_pl2[i], \"hrv\"))\n",
    "\n",
    "total_score = 0\n",
    "for i in range(n):\n",
    "  bleu = sentence_bleu([hr[:n][i].split(' ')], pl_back2[i].split(' '))\n",
    "  total_score += bleu\n",
    "print(\"BLEU score: \", total_score/n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41bQqU9CYwoq"
   },
   "source": [
    "Text results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 588
    },
    "id": "r9HcZCVMICop",
    "outputId": "bb221ba3-1038-4952-f52a-87316cf02769"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_bd0c9_row0_col0, #T_bd0c9_row0_col1, #T_bd0c9_row0_col2, #T_bd0c9_row0_col3, #T_bd0c9_row0_col4, #T_bd0c9_row0_col5, #T_bd0c9_row1_col0, #T_bd0c9_row1_col1, #T_bd0c9_row1_col2, #T_bd0c9_row1_col3, #T_bd0c9_row1_col4, #T_bd0c9_row1_col5, #T_bd0c9_row2_col0, #T_bd0c9_row2_col1, #T_bd0c9_row2_col2, #T_bd0c9_row2_col3, #T_bd0c9_row2_col4, #T_bd0c9_row2_col5, #T_bd0c9_row3_col0, #T_bd0c9_row3_col1, #T_bd0c9_row3_col2, #T_bd0c9_row3_col3, #T_bd0c9_row3_col4, #T_bd0c9_row3_col5, #T_bd0c9_row4_col0, #T_bd0c9_row4_col1, #T_bd0c9_row4_col2, #T_bd0c9_row4_col3, #T_bd0c9_row4_col4, #T_bd0c9_row4_col5 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_bd0c9\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_bd0c9_level0_col0\" class=\"col_heading level0 col0\" >Original Polish</th>\n",
       "      <th id=\"T_bd0c9_level0_col1\" class=\"col_heading level0 col1\" >Reference Croatian</th>\n",
       "      <th id=\"T_bd0c9_level0_col2\" class=\"col_heading level0 col2\" >mBART-50 Translation Polish</th>\n",
       "      <th id=\"T_bd0c9_level0_col3\" class=\"col_heading level0 col3\" >mBART-50 Translation Croatian</th>\n",
       "      <th id=\"T_bd0c9_level0_col4\" class=\"col_heading level0 col4\" >MarianMT Translation Polish</th>\n",
       "      <th id=\"T_bd0c9_level0_col5\" class=\"col_heading level0 col5\" >MarianMT Translation Croatian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_bd0c9_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_bd0c9_row0_col0\" class=\"data row0 col0\" >Błędna jest opinia, że rozwój mowy rozpoczyna się od momentu pierwszych słów. </td>\n",
       "      <td id=\"T_bd0c9_row0_col1\" class=\"data row0 col1\" >Pogrešno je mišljenje da razvoj govora počinje od trenutka prvih riječi. </td>\n",
       "      <td id=\"T_bd0c9_row0_col2\" class=\"data row0 col2\" >Błędnie uważamy, że rozwój języka zaczyna się od momentu pierwszych słów.</td>\n",
       "      <td id=\"T_bd0c9_row0_col3\" class=\"data row0 col3\" >Błędna je ideja da se razvoj govora počinje od trenutka prve riječi.</td>\n",
       "      <td id=\"T_bd0c9_row0_col4\" class=\"data row0 col4\" >Niewłaściwe jest opinia, że rozwój mowy zaczyna się od momentu pierwszych słów.</td>\n",
       "      <td id=\"T_bd0c9_row0_col5\" class=\"data row0 col5\" >Pogrešno je zaključiti da je razvoj govora počeo od početka prvih riječi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bd0c9_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_bd0c9_row1_col0\" class=\"data row1 col0\" >Jednak jeśli jesteś jednym z bezwłosy lub utrata włosów wokół osoby, czynnik potencjalnie nie jest faktycznie największym zmartwieniem swoją dzisiaj. </td>\n",
       "      <td id=\"T_bd0c9_row1_col1\" class=\"data row1 col1\" >Ipak, ako ste jedan od dlaka ili gubitak ljudi kose oko, razlog potencijalno zapravo nije vaša najveća briga danas. </td>\n",
       "      <td id=\"T_bd0c9_row1_col2\" class=\"data row1 col2\" >Jednak, if you're one of the hair-losers, the reason, potentially, isn't your biggest concern today.</td>\n",
       "      <td id=\"T_bd0c9_row1_col3\" class=\"data row1 col3\" >No, if you are one of baldness or hair loss around a person, the factor potentially isn’t actually your biggest concern today.</td>\n",
       "      <td id=\"T_bd0c9_row1_col4\" class=\"data row1 col4\" >Mimo to, jeśli jesteś jednym z włosów lub straty ludzi, to powód potencjalnie nie jest twoim największym problemem dzisiaj.</td>\n",
       "      <td id=\"T_bd0c9_row1_col5\" class=\"data row1 col5\" >Međutim, ako ste jedan od bezkosa ili gubitak kose oko osobe, potencijalno nije zapravo najveća zabrinutost danas.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bd0c9_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_bd0c9_row2_col0\" class=\"data row2 col0\" >Wojna dopiero się zaczyna... </td>\n",
       "      <td id=\"T_bd0c9_row2_col1\" class=\"data row2 col1\" >Rat je tek počeo... </td>\n",
       "      <td id=\"T_bd0c9_row2_col2\" class=\"data row2 col2\" >Wojna dopiero się rozpoczęła...</td>\n",
       "      <td id=\"T_bd0c9_row2_col3\" class=\"data row2 col3\" >Wojna tek počinje...</td>\n",
       "      <td id=\"T_bd0c9_row2_col4\" class=\"data row2 col4\" >Wojna dopiero się zaczęła.</td>\n",
       "      <td id=\"T_bd0c9_row2_col5\" class=\"data row2 col5\" >Rat je tek počeo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bd0c9_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_bd0c9_row3_col0\" class=\"data row3 col0\" >Upadek Turtle prowadzi spadkobierców w przeglądzie woli Westinga, aby pozbyć się prawdziwego znaczenia. </td>\n",
       "      <td id=\"T_bd0c9_row3_col1\" class=\"data row3 col1\" >Pada djelovanje Kornjača vodi nasljednike u pregledu Westingove volje kako bi razjasnio svoje pravo značenje. </td>\n",
       "      <td id=\"T_bd0c9_row3_col2\" class=\"data row3 col2\" >The dropping of the Koran leads to a review of Westing's will to clarify its true meaning.</td>\n",
       "      <td id=\"T_bd0c9_row3_col3\" class=\"data row3 col3\" >Turtle's fall leads heirs to a review of Westing's will to get rid of his true significance.</td>\n",
       "      <td id=\"T_bd0c9_row3_col4\" class=\"data row3 col4\" >Działanie żółwia prowadzi spadkobierców do przeglądu woli Westinga, by wyjaśnić swoje prawdziwe znaczenie.</td>\n",
       "      <td id=\"T_bd0c9_row3_col5\" class=\"data row3 col5\" >Opadanje kornjače vodi nasljednike u pregledu volje Westing da se riješi pravog značenja.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bd0c9_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_bd0c9_row4_col0\" class=\"data row4 col0\" >Średnia ocena naszych byłych uczniów, na pytanie o ich cały pobyt w szkole w Frankfurt </td>\n",
       "      <td id=\"T_bd0c9_row4_col1\" class=\"data row4 col1\" >Prosječna ocjena od naših bivših učenika, kada smo ih pitali za njihov ukupan boravak u školi u Frankfurt </td>\n",
       "      <td id=\"T_bd0c9_row4_col2\" class=\"data row4 col2\" >Średnia ocena naszych byłych uczniów, kiedy pytaliśmy o ich uczęszczanie do szkoły w Frankfurt.</td>\n",
       "      <td id=\"T_bd0c9_row4_col3\" class=\"data row4 col3\" >Średnja ocena naših bivših studenata, na pitanje o njihovom cijelom stayu u školi u Frankfurtu</td>\n",
       "      <td id=\"T_bd0c9_row4_col4\" class=\"data row4 col4\" >Średnia ocena naszych byłych uczniów, kiedy zapytaliśmy ich o ich wspólne pobyt w szkole w Frankfurt</td>\n",
       "      <td id=\"T_bd0c9_row4_col5\" class=\"data row4 col5\" >Prosječna procjena naših bivših učenika, na pitanje o njihovom cijelom boravku u školi u Frankfurtu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7b624bcf3440>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples = pd.DataFrame({\n",
    "    'Original Polish': pl[:5],\n",
    "    'Reference Croatian': hr[:5],\n",
    "    'mBART-50 Translation Polish': hr_to_pl[:5],\n",
    "    'mBART-50 Translation Croatian': pl_to_hr[:5],\n",
    "    'MarianMT Translation Polish': hr_to_pl2[:5],\n",
    "    'MarianMT Translation Croatian': pl_to_hr2[:5]\n",
    "})\n",
    "\n",
    "display(samples.style.set_properties(**{'text-align': 'left'}))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "state": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
