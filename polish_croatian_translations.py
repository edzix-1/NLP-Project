# -*- coding: utf-8 -*-
"""Polish-Croatian-translations.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qUXn9rluOBpVrSKaIvWSokChnhFlX7Fc

Code responsible for downloading and unpacking the data
"""

import urllib.request

url = "https://object.pouta.csc.fi/OPUS-MultiParaCrawl/v7.1/moses/hr-pl.txt.zip"
output_path = "opus_pl_hr.zip"

urllib.request.urlretrieve(url, output_path)
print("Download complete")

!unzip -o opus_pl_hr.zip

import pandas as pd
from nltk.translate.bleu_score import sentence_bleu

with open("MultiParaCrawl.hr-pl.hr", "r", encoding="utf-8") as f: hr = f.read().splitlines()
with open("MultiParaCrawl.hr-pl.pl", "r", encoding="utf-8") as f: pl = f.read().splitlines()

df = pd.DataFrame({"hr": hr, "pl": pl})
n = 300

"""Multilingual model and tokenizer declaration. Creating the translate function for the Multilingual model."""

from transformers import MBartForConditionalGeneration, MBart50TokenizerFast

model = MBartForConditionalGeneration.from_pretrained("facebook/mbart-large-50-many-to-many-mmt")
tokenizer = MBart50TokenizerFast.from_pretrained("facebook/mbart-large-50-many-to-many-mmt")

def translate_multi(sentences, src_lang, tgt_lang):
    output = []
    tokenizer.src_lang = src_lang
    for sentence in sentences:
      encoded = tokenizer(sentence, return_tensors="pt")

      generated_tokens = model.generate(
          **encoded,
          forced_bos_token_id=tokenizer.lang_code_to_id[tgt_lang]
      )
      output.append(tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0])

    return output

"""Back-and-forth translations and evaluations for the Multilingual model"""

hr_to_pl = translate_multi(hr[:n], "hr_HR", "pl_PL")

total_score = 0
for i in range(n):
  bleu = sentence_bleu([list(pl[:n][i])], list(hr_to_pl[i]))
  total_score += bleu
print("BLEU score: ", total_score/n)

pl_back = translate_multi(hr_to_pl, "pl_PL", "hr_HR")
total_score = 0
for i in range(n):
  bleu = sentence_bleu([list(hr[:n][i])], list(pl_back[i]))
  total_score += bleu
print("BLEU score: ", total_score/n)

pl_to_hr = translate_multi(pl[:n], "pl_PL", "hr_HR")
total_score = 0
for i in range(n):
  bleu = sentence_bleu([list(pl[:n][i])], list(pl_to_hr[i]))
  total_score += bleu
print("BLEU score: ", total_score/n)

hr_back = translate_multi(pl_to_hr, "hr_HR", "pl_PL")
total_score = 0
for i in range(n):
  bleu = sentence_bleu([list(hr[:n][i])], list(hr_back[i]))
  total_score += bleu
print("BLEU score: ", total_score/n)

"""Translations through English"""

ht_to_en = translate_multi(hr[:n], "hr_HR", "en_XX")
en_to_pl = translate_multi(ht_to_en, "en_XX", "pl_PL")
total_score = 0
for i in range(n):
  bleu = sentence_bleu([list(pl[:n][i])], list(en_to_pl[i]))
  total_score += bleu
print("BLEU score: ", total_score/n)

"""Slavic model and tokenizer declaration. Creating the translate function for the Slavic model."""

from transformers import MarianMTModel, MarianTokenizer

model_name = 'Helsinki-NLP/opus-mt-sla-sla'
tokenizer = MarianTokenizer.from_pretrained(model_name)
model = MarianMTModel.from_pretrained(model_name)
def translate(text, trg_lang):
    text = ">>" + trg_lang + "<< " + text
    translated = model.generate(**tokenizer(text, return_tensors='pt', padding=True))

    translated_text = tokenizer.decode(translated[0], skip_special_tokens=True)

    return translated_text

"""Back-and-forth translations and evaluations for the Slavic model"""

hr_to_pl2 = []
for i in range(n):
  hr_to_pl2.append(translate(hr[i], "pol"))

total_score = 0
for i in range(n):
  bleu = sentence_bleu([list(pl[:n][i])], list(hr_to_pl2[i]))
  total_score += bleu
print("BLEU score: ", total_score/n)

pl_to_hr2 = []
for i in range(n):
  pl_to_hr2.append(translate(pl[i], "hrv"))

total_score = 0
for i in range(n):
  bleu = sentence_bleu([list(hr[:n][i])], list(pl_to_hr2[i]))
  total_score += bleu
print("BLEU score: ", total_score/n)

hr_back2 = []
for i in range(n):
  hr_back2.append(translate(pl_to_hr2[i], "pol"))

total_score = 0
for i in range(n):
  bleu = sentence_bleu([list(pl[:n][i])], list(hr_back2[i]))
  total_score += bleu
print("BLEU score: ", total_score/n)

pl_back2 = []
for i in range(n):
  pl_back2.append(translate(hr_to_pl2[i], "hrv"))

total_score = 0
for i in range(n):
  bleu = sentence_bleu([list(hr[:n][i])], list(pl_back2[i]))
  total_score += bleu
print("BLEU score: ", total_score/n)

"""Text results"""

hr_to_pl

pl_back

pl_to_hr

hr_back

en_to_pl

pl[:n]

hr_to_pl2

hr_back2